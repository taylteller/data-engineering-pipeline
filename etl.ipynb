{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Immigration Data Pipeline\n",
    "## Udacity Data Engineering Capstone Project\n",
    "\n",
    "### Project Summary\n",
    "The purpose of this project is to create an ETL pipeline that wrangles data on immigration, demographics and environmental factors (specifically temperature), in order to be able to glean insights about what factors may make certain US destination popular for international visits. Example questions that business users may want answered include:\n",
    "* Is there a correlation between a visitor's home temperature and the temperature of their chosen destination?\n",
    "* Do people from certain countries prefer destination cities where certain ethnicities are better represented?\n",
    "* Are particular destinations more popular with holders of visas of a certain type?\n",
    "\n",
    "We'll be using Spark to process the data.\n",
    "\n",
    "The project is broken down into 5 steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Clean Up the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Let's get ready by importing the libraries and tools we'll be using...\n",
    "\n",
    "import pandas as pd\n",
    "import helpers\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date, upper, first, dayofmonth, weekofyear, month, year, dayofweek, udf, monotonically_increasing_id, datediff\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# ...and initializing our SparkSession\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "config('spark.jars.repositories', 'https://repos.spark-packages.org/').\\\n",
    "config('spark.jars.packages', 'saurfang:spark-sas7bdat:2.0.0-s_2.11').\\\n",
    "enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1: Scoping the Project and Gathering Data\n",
    "\n",
    "### Scope \n",
    "We have various data on immigration, travel, temperature and demographics, from various sources. The business need is to be able to query the data to see what factors may affect immigration or US travel destination choices. More specifically, the goal is to create a set of relational tables against which we can run queries to look for patterns between chosen immigration or travel destination, and demographic and environmental factors.\n",
    "\n",
    "To accomplish this, Spark will be used, as it is well suited to process large amounts of data across multiple servers. If we wanted to take the project further, we could migrate the output data into a suitable RDBMS, like Redshift, and we could automate the pipleline with Airflow; this, however, is outside the scope of this particular project. The primary goal and scope of the task here is to explore the data, model it and load it into relational tables suitable for analytic querying.\n",
    "\n",
    "\n",
    "### Describing and Gathering the Data \n",
    "The source data are the following:\n",
    "\n",
    "* _I94 Immigration Data_: This data comes from the [US National Tourism and Trade Office](https://www.trade.gov/i-94-arrivals-program). It consists of the 2016 I-94 visitor arrivals data, providing information on arrivals for US visitors who stay 1 night or more. The link to the original dataset is defunct, but a copy of the data was captured and provided by Udacity.\n",
    "* _World Temperature Data_: [This dataset](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data) was sourced from Kaggle. It consists of a table of global land temperatures by city and by month, from approximately 1750.\n",
    "* _U.S. City Demographic Data_: [This data](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/) comes from OpenSoft. The data is compiled from the US Census Bureau's 2015 American Community Survey. It contains demographic information for all US cities that have a population of 65,000 or more. \n",
    "* _Airport Code Table_: [This](https://datahub.io/core/airport-codes#data) is a table of airport codes and corresponding cities.\n",
    "\n",
    "To create the relational tables that will allows us to explore demographic and environmental correlations, we will only need data from the first three sets. We will not be using the _Airport Code Table_ dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 2: Exploring and Cleaning Up the Data\n",
    "Let's identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "Some of this data was explored \"offline\", so to speak; information was gathered by visiting the original sources for the datasets or via supplemental contextual information. The i94 dataset, particularly, benefited from this; the definitions of the columns was understood primarily through looking at the `I94_SAS_Labels_Descriptions.SAS` file located in the same directory as this README file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Exploration\n",
    "#### Immigration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the i94 data\n",
    "i94_df = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN    None   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U     None   1979.0  10282016   None   None   \n",
       "1      NaN   ...           Y     None   1991.0       D/S      M   None   \n",
       "2  20691.0   ...        None        M   1961.0  09302016      M   None   \n",
       "3  20567.0   ...        None        M   1988.0  09302016   None   None   \n",
       "4  20567.0   ...        None        M   2012.0  09302016   None   None   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0    None  1.897628e+09   None       B2  \n",
       "1    None  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a preview\n",
    "i94_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column name</th>\n",
       "      <th>total missing</th>\n",
       "      <th>% missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cicid</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i94yr</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i94mon</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i94cit</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i94res</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i94port</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arrdate</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i94mode</td>\n",
       "      <td>239</td>\n",
       "      <td>0.007719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i94addr</td>\n",
       "      <td>152592</td>\n",
       "      <td>4.928184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>depdate</td>\n",
       "      <td>142457</td>\n",
       "      <td>4.600859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>i94bir</td>\n",
       "      <td>802</td>\n",
       "      <td>0.025902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>i94visa</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>count</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dtadfile</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>visapost</td>\n",
       "      <td>1881250</td>\n",
       "      <td>60.757746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>occup</td>\n",
       "      <td>3088187</td>\n",
       "      <td>99.737559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>entdepa</td>\n",
       "      <td>238</td>\n",
       "      <td>0.007687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>entdepd</td>\n",
       "      <td>138429</td>\n",
       "      <td>4.470769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>entdepu</td>\n",
       "      <td>3095921</td>\n",
       "      <td>99.987340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>matflag</td>\n",
       "      <td>138429</td>\n",
       "      <td>4.470769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>biryear</td>\n",
       "      <td>802</td>\n",
       "      <td>0.025902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dtaddto</td>\n",
       "      <td>477</td>\n",
       "      <td>0.015405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gender</td>\n",
       "      <td>414269</td>\n",
       "      <td>13.379429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>insnum</td>\n",
       "      <td>2982605</td>\n",
       "      <td>96.327632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>airline</td>\n",
       "      <td>83627</td>\n",
       "      <td>2.700857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>admnum</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>fltno</td>\n",
       "      <td>19549</td>\n",
       "      <td>0.631364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>visatype</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   column name  total missing  % missing\n",
       "0        cicid              0   0.000000\n",
       "1        i94yr              0   0.000000\n",
       "2       i94mon              0   0.000000\n",
       "3       i94cit              0   0.000000\n",
       "4       i94res              0   0.000000\n",
       "5      i94port              0   0.000000\n",
       "6      arrdate              0   0.000000\n",
       "7      i94mode            239   0.007719\n",
       "8      i94addr         152592   4.928184\n",
       "9      depdate         142457   4.600859\n",
       "10      i94bir            802   0.025902\n",
       "11     i94visa              0   0.000000\n",
       "12       count              0   0.000000\n",
       "13    dtadfile              1   0.000032\n",
       "14    visapost        1881250  60.757746\n",
       "15       occup        3088187  99.737559\n",
       "16     entdepa            238   0.007687\n",
       "17     entdepd         138429   4.470769\n",
       "18     entdepu        3095921  99.987340\n",
       "19     matflag         138429   4.470769\n",
       "20     biryear            802   0.025902\n",
       "21     dtaddto            477   0.015405\n",
       "22      gender         414269  13.379429\n",
       "23      insnum        2982605  96.327632\n",
       "24     airline          83627   2.700857\n",
       "25      admnum              0   0.000000\n",
       "26       fltno          19549   0.631364\n",
       "27    visatype              0   0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the total of null or NaN values per column\n",
    "helpers.show_total_missing_values(i94_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the demographic data\n",
    "demog_df = spark.read.csv('us-cities-demographics.csv', inferSchema=True, header=True, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8            40601   \n",
       "1            Quincy  Massachusetts        41.0            44129   \n",
       "2            Hoover        Alabama        38.5            38040   \n",
       "3  Rancho Cucamonga     California        34.5            88127   \n",
       "4            Newark     New Jersey        34.6           138040   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0              41862             82463                1562         30908   \n",
       "1              49500             93629                4147         32935   \n",
       "2              46799             84839                4819          8229   \n",
       "3              87105            175232                5821         33878   \n",
       "4             143873            281913                5829         86253   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a preview\n",
    "demog_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column name</th>\n",
       "      <th>total missing</th>\n",
       "      <th>% missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>State</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Median Age</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male Population</td>\n",
       "      <td>3</td>\n",
       "      <td>0.103770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female Population</td>\n",
       "      <td>3</td>\n",
       "      <td>0.103770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Total Population</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Number of Veterans</td>\n",
       "      <td>13</td>\n",
       "      <td>0.449671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Foreign-born</td>\n",
       "      <td>13</td>\n",
       "      <td>0.449671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Average Household Size</td>\n",
       "      <td>16</td>\n",
       "      <td>0.553442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>State Code</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Race</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Count</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               column name  total missing  % missing\n",
       "0                     City              0   0.000000\n",
       "1                    State              0   0.000000\n",
       "2               Median Age              0   0.000000\n",
       "3          Male Population              3   0.103770\n",
       "4        Female Population              3   0.103770\n",
       "5         Total Population              0   0.000000\n",
       "6       Number of Veterans             13   0.449671\n",
       "7             Foreign-born             13   0.449671\n",
       "8   Average Household Size             16   0.553442\n",
       "9               State Code              0   0.000000\n",
       "10                    Race              0   0.000000\n",
       "11                   Count              0   0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the total of null or NaN values per column\n",
    "helpers.show_total_missing_values(demog_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the temperature data\n",
    "temp_df = spark.read.csv('../../data2/GlobalLandTemperaturesByCity.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0 1743-11-01               6.068                          1.737  Århus   \n",
       "1 1743-12-01                 NaN                            NaN  Århus   \n",
       "2 1744-01-01                 NaN                            NaN  Århus   \n",
       "3 1744-02-01                 NaN                            NaN  Århus   \n",
       "4 1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a preview\n",
    "temp_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column name</th>\n",
       "      <th>total missing</th>\n",
       "      <th>% missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AverageTemperature</td>\n",
       "      <td>364130</td>\n",
       "      <td>4.234458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AverageTemperatureUncertainty</td>\n",
       "      <td>364130</td>\n",
       "      <td>4.234458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>City</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Country</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Latitude</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Longitude</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     column name  total missing  % missing\n",
       "0                             dt              0   0.000000\n",
       "1             AverageTemperature         364130   4.234458\n",
       "2  AverageTemperatureUncertainty         364130   4.234458\n",
       "3                           City              0   0.000000\n",
       "4                        Country              0   0.000000\n",
       "5                       Latitude              0   0.000000\n",
       "6                      Longitude              0   0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the total of null or NaN values per column, but first we cast the datetime column to string\n",
    "temp_df_string = temp_df.withColumn('dt', col('dt').cast(StringType()))\n",
    "helpers.show_total_missing_values(temp_df_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Clean Up\n",
    "\n",
    "#### Immigration Data\n",
    "If we look again at the table of total missing values per column in the _Exploration_ section, we can see that three columns have a total of more than 85% missing values: `occup`, `entdepu`, and `insnum`. These can be dropped.\n",
    "\n",
    "Taking this a step further, as we'll see shortly in our data model, there are only 11 columns we're interested in keeping. Let's select these to make the dataframe easier to work with and more legible to display. While we're at it, let's rename those columns and drop duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_df = i94_df.select(col('cicid').alias('id'),\n",
    "                             col('i94cit').alias('citizenship_country'),\n",
    "                             col('i94res').alias('residence_country'),\n",
    "                             col('i94port').alias('port_of_entry'),\n",
    "                             col('i94addr').alias('destination_state'),\n",
    "                             col('arrdate').alias('arrival_date'),\n",
    "                             col('depdate').alias('departure_date'),\n",
    "                             col('i94bir').alias('age'),\n",
    "                             col('i94visa').alias('visa_type'),\n",
    "                             col('dtaddto').alias('admitted_until'),\n",
    "                             col('gender').alias('gender')\n",
    "                            ).dropDuplicates().cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We'll also convert the SAS dates in `arrdate` and `depdate`, and the string date in `dtaddto`, to PySpark dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_df = i94_df.withColumn('arrival_date', helpers.convert_sas_date_to_datetime(i94_df.arrival_date)).cache()\n",
    "i94_df = i94_df.withColumn('departure_date', helpers.convert_sas_date_to_datetime(i94_df.departure_date)).cache()\n",
    "i94_df = i94_df.withColumn('admitted_until', to_date(col('admitted_until'),'MMddyyyy')).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>citizenship_country</th>\n",
       "      <th>residence_country</th>\n",
       "      <th>port_of_entry</th>\n",
       "      <th>destination_state</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>age</th>\n",
       "      <th>visa_type</th>\n",
       "      <th>admitted_until</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>246.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>645.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>FL</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-06</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>660.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-05-15</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>674.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>NEW</td>\n",
       "      <td>CT</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-10</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>788.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>FL</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-15</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  citizenship_country  residence_country port_of_entry  \\\n",
       "0  246.0                103.0              103.0           NYC   \n",
       "1  645.0                103.0              103.0           MIA   \n",
       "2  660.0                103.0              104.0           SFR   \n",
       "3  674.0                103.0              131.0           NEW   \n",
       "4  788.0                104.0              104.0           ATL   \n",
       "\n",
       "  destination_state arrival_date departure_date   age  visa_type  \\\n",
       "0                NY   2016-04-01     2016-04-08  40.0        2.0   \n",
       "1                FL   2016-04-01     2016-04-06  32.0        1.0   \n",
       "2                CA   2016-04-01     2016-05-15  38.0        2.0   \n",
       "3                CT   2016-04-01     2016-04-10  29.0        2.0   \n",
       "4                FL   2016-04-01     2016-04-15  38.0        2.0   \n",
       "\n",
       "  admitted_until gender  \n",
       "0     2016-06-29      M  \n",
       "1     2016-09-30      M  \n",
       "2     2016-06-29      M  \n",
       "3     2016-06-29      F  \n",
       "4     2016-06-29      F  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We can see that the fields `citizenship_country`, `residence_country`, and `state_of_arrival` are referenced by codes. These need to be cross-referenced with a list of codes that is currently only available in a .SAS file. We'll update these values with their full names.\n",
    "\n",
    "We also have the `port_of_entry` field in the i94 table, which we can decompose into port city, port state, and port country. Doing this will later on allow us to add the port code to the temperature and demographic tables, which will allow us to keep our fact table simple, as a single field (`port_of_entry`) will be able to link three dimension tables together. \n",
    "\n",
    "All of this will serve to:\n",
    "1. make the values in our tables more meaningful, and\n",
    "2. make it easier to join tables when querying by reducing the number of joins and tables involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read our i94 fields and values legend \n",
    "with open('I94_SAS_Labels_Descriptions.SAS') as f:\n",
    "    i94_desc = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get country names by code\n",
    "country_codes = {}\n",
    "for countries in i94_desc[10:298]:\n",
    "    pair = countries.split('=')\n",
    "    code, country = pair[0].strip(), pair[1].strip().strip(\"'\")\n",
    "    country_codes[code] = country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "origin_countries_df = spark.createDataFrame(list(country_codes.items()), ['code', 'country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>324</td>\n",
       "      <td>ANGOLA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code      country\n",
       "0  236  AFGHANISTAN\n",
       "1  101      ALBANIA\n",
       "2  316      ALGERIA\n",
       "3  102      ANDORRA\n",
       "4  324       ANGOLA"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_countries_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get city names and state abbreviations by numerical codes\n",
    "port_cities = {}\n",
    "port_states = {}\n",
    "broken_fields = {}\n",
    "for cities in i94_desc[303:893]:   \n",
    "    pair = cities.split('=')\n",
    "    code, location = pair[0].strip(\"\\t\").strip().strip(\"'\"), pair[1].strip('\\t').strip()\n",
    "    city_and_state = location.split(',')\n",
    "    if len(city_and_state) == 2:\n",
    "        city, state = city_and_state[0].strip().strip(\"'\"), city_and_state[1].strip().strip(\"'\").strip()\n",
    "        port_cities[code] = city\n",
    "        port_states[code] = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "port_cities_df = spark.createDataFrame(list(port_cities.items()), ['code', 'city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTH</td>\n",
       "      <td>DUTCH HARBOR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code                      city\n",
       "0  ANC                 ANCHORAGE\n",
       "1  BAR  BAKER AAF - BAKER ISLAND\n",
       "2  DAC             DALTONS CACHE\n",
       "3  PIZ    DEW STATION PT LAY DEW\n",
       "4  DTH              DUTCH HARBOR"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port_cities_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get state names by state abbreviation\n",
    "state_abbrs = {}\n",
    "for states in i94_desc[982:1035]:   \n",
    "    pair = states.split('=')\n",
    "    abbr, state = pair[0].strip(\"\\t\").strip().strip(\"'\"), pair[1].strip('\\t').strip().strip(\"'\")\n",
    "    if 'N.' in state:\n",
    "        state = state.replace('N.','NORTH')\n",
    "    if 'S.' in state:\n",
    "        state = state.replace('S.','SOUTH')\n",
    "    if 'W.' in state:\n",
    "        state = state.replace('W.','WEST')\n",
    "    if 'DIST.' in state:\n",
    "        state = state.replace('DIST.','DISTRICT')\n",
    "    state_abbrs[abbr] = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "port_countries = {}\n",
    "for code in port_states: \n",
    "    if port_states[code] in state_abbrs:\n",
    "        port_states[code] = state_abbrs[port_states[code]]\n",
    "        port_countries[code] = 'UNITED STATES'\n",
    "    else:\n",
    "        port_countries[code] = port_states[code]\n",
    "        port_states[code] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "state_abbrs_df = spark.createDataFrame(list(state_abbrs.items()), ['abbr','state'])\n",
    "port_states_df = spark.createDataFrame(list(port_states.items()), ['code','state'])\n",
    "port_countries_df = spark.createDataFrame(list(port_countries.items()), ['code','country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abbr</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZ</td>\n",
       "      <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CO</td>\n",
       "      <td>COLORADO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abbr       state\n",
       "0   AK      ALASKA\n",
       "1   AZ     ARIZONA\n",
       "2   AR    ARKANSAS\n",
       "3   CA  CALIFORNIA\n",
       "4   CO    COLORADO"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_abbrs_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAR</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAC</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTH</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code   state\n",
       "0  ANC  ALASKA\n",
       "1  BAR  ALASKA\n",
       "2  DAC  ALASKA\n",
       "3  PIZ  ALASKA\n",
       "4  DTH  ALASKA"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port_states_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANC</td>\n",
       "      <td>UNITED STATES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAR</td>\n",
       "      <td>UNITED STATES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAC</td>\n",
       "      <td>UNITED STATES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>UNITED STATES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTH</td>\n",
       "      <td>UNITED STATES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code        country\n",
       "0  ANC  UNITED STATES\n",
       "1  BAR  UNITED STATES\n",
       "2  DAC  UNITED STATES\n",
       "3  PIZ  UNITED STATES\n",
       "4  DTH  UNITED STATES"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port_countries_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create views from the dictionary dataframes we just created, \n",
    "# so we can use sql to add meaningful port city, state and country values to our i94 table\n",
    "i94_df.createOrReplaceTempView('i94_view')\n",
    "origin_countries_df.createOrReplaceTempView('origin_countries_view')\n",
    "state_abbrs_df.createOrReplaceTempView('state_abbrs_view')\n",
    "port_cities_df.createOrReplaceTempView('port_cities_view')\n",
    "port_states_df.createOrReplaceTempView('port_states_view')\n",
    "port_countries_df.createOrReplaceTempView('port_countries_view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# clean up our i94 table by converting codes to human-readable values\n",
    "i94_clean_df = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        i94.id AS immigration_id,\n",
    "        i94.age AS age,\n",
    "        i94.gender AS gender,\n",
    "        c_cit.country AS citizenship_country,\n",
    "        c_res.country AS residence_country,\n",
    "        i94.arrival_date AS arrival_date,\n",
    "        i94.departure_date AS departure_date,\n",
    "        i94.visa_type AS visa_type,\n",
    "        i94.admitted_until AS admitted_until,\n",
    "        i94.port_of_entry AS port_of_entry,\n",
    "        p_cit.city AS port_city,\n",
    "        ps.state AS port_state,\n",
    "        p_country.country AS port_country,\n",
    "        sa.state AS destination_state\n",
    "    FROM i94_view i94\n",
    "    \n",
    "    -- retrieve the country names of the code values in i94.citizenship_country\n",
    "    LEFT JOIN origin_countries_view c_cit\n",
    "    ON i94.citizenship_country = c_cit.code\n",
    "    \n",
    "    -- retrieve the country names of the code values in i94.residence_country\n",
    "    LEFT JOIN origin_countries_view c_res\n",
    "    ON i94.residence_country = c_res.code\n",
    "    \n",
    "    -- retrieve the city names of the code values in i94.port_of_entry\n",
    "    LEFT JOIN port_cities_view p_cit\n",
    "    ON i94.port_of_entry = p_cit.code\n",
    "    \n",
    "    -- retrieve the state names of the code values in i94.port_of_entry, if applicable\n",
    "    LEFT JOIN port_states_view ps\n",
    "    ON i94.port_of_entry = ps.code\n",
    "    \n",
    "    -- retrieve the country names of the code values in i94.port_of_entry\n",
    "    LEFT JOIN port_countries_view p_country\n",
    "    ON i94.port_of_entry = p_country.code\n",
    "    \n",
    "    -- retrieve the full state names of the state abbreviations in i94.destination_state\n",
    "    LEFT JOIN state_abbrs_view sa\n",
    "    ON i94.destination_state = sa.abbr\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_clean_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>immigration_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>citizenship_country</th>\n",
       "      <th>residence_country</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>visa_type</th>\n",
       "      <th>admitted_until</th>\n",
       "      <th>port_of_entry</th>\n",
       "      <th>port_city</th>\n",
       "      <th>port_state</th>\n",
       "      <th>port_country</th>\n",
       "      <th>destination_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4651287.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-10-24</td>\n",
       "      <td>NEW</td>\n",
       "      <td>NEWARK/TETERBORO</td>\n",
       "      <td>NEW JERSEY</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014736.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>GERMANY</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>2016-04-15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-07-09</td>\n",
       "      <td>HOU</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2093085.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>2016-04-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-10-11</td>\n",
       "      <td>HOU</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>998502.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>M</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>2016-04-06</td>\n",
       "      <td>2016-04-10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-07-04</td>\n",
       "      <td>HOU</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1373083.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>None</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   immigration_id   age gender citizenship_country residence_country  \\\n",
       "0       4651287.0  45.0      F                None              None   \n",
       "1       2014736.0  38.0   None                None           GERMANY   \n",
       "2       2093085.0  46.0      M                None              None   \n",
       "3        998502.0  32.0      M               SPAIN             SPAIN   \n",
       "4       1373083.0  22.0   None      UNITED KINGDOM    UNITED KINGDOM   \n",
       "\n",
       "  arrival_date departure_date  visa_type admitted_until port_of_entry  \\\n",
       "0   2016-04-24     2016-04-29        2.0     2016-10-24           NEW   \n",
       "1   2016-04-11     2016-04-15        2.0     2016-07-09           HOU   \n",
       "2   2016-04-11     2016-04-15        1.0     2016-10-11           HOU   \n",
       "3   2016-04-06     2016-04-10        2.0     2016-07-04           HOU   \n",
       "4   2016-04-08     2016-04-09        1.0     2016-10-07           ATL   \n",
       "\n",
       "          port_city  port_state   port_country destination_state  \n",
       "0  NEWARK/TETERBORO  NEW JERSEY  UNITED STATES              None  \n",
       "1           HOUSTON       TEXAS  UNITED STATES              None  \n",
       "2           HOUSTON       TEXAS  UNITED STATES              None  \n",
       "3           HOUSTON       TEXAS  UNITED STATES              None  \n",
       "4           ATLANTA     GEORGIA  UNITED STATES              None  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_clean_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|   destination_state| count|\n",
      "+--------------------+------+\n",
      "|          NEW JERSEY| 76531|\n",
      "|        PENNSYLVANIA| 30293|\n",
      "|            ILLINOIS| 82126|\n",
      "|DISTRICT OF COLUMBIA| 28228|\n",
      "|            MARYLAND| 25360|\n",
      "|       WEST VIRGINIA|   808|\n",
      "|               IDAHO|  1752|\n",
      "|            MISSOURI|  8484|\n",
      "|             MONTANA|  1339|\n",
      "|            MICHIGAN| 32101|\n",
      "|             FLORIDA|621701|\n",
      "|                null|187354|\n",
      "|              OREGON| 12574|\n",
      "|        SOUTH DAKOTA|   557|\n",
      "|           LOUISIANA| 22655|\n",
      "|              ALASKA|  1604|\n",
      "|         PUERTO RICO|  9474|\n",
      "|      VIRGIN ISLANDS|   226|\n",
      "|               MAINE|  2361|\n",
      "|       NEW HAMPSHIRE|  2817|\n",
      "|            OKLAHOMA|  3239|\n",
      "|            VIRGINIA| 31399|\n",
      "|          WASHINGTON| 55792|\n",
      "|      NORTH CAROLINA| 23375|\n",
      "|             WYOMING|   460|\n",
      "|               TEXAS|134321|\n",
      "|            NEBRASKA| 26574|\n",
      "|           MINNESOTA| 11194|\n",
      "|              HAWAII|168764|\n",
      "|                GUAM| 94107|\n",
      "|        RHODE ISLAND|  3289|\n",
      "|         MISSISSIPPI|  1771|\n",
      "|           TENNESSEE| 12105|\n",
      "|           WISCONSON|  7860|\n",
      "|            COLORADO| 15874|\n",
      "|              NEVADA|114609|\n",
      "|             VERMONT|  1477|\n",
      "|          NEW MEXICO|  1994|\n",
      "|            NEW YORK|553677|\n",
      "|                UTAH|  7551|\n",
      "|          CALIFORNIA|470386|\n",
      "|                IOWA|  3391|\n",
      "|              KANSAS|  3224|\n",
      "|             ARIZONA| 20218|\n",
      "|            KENTUCKY|  5790|\n",
      "|                OHIO| 18089|\n",
      "|       MASSACHUSETTS| 70486|\n",
      "|      SOUTH CAROLINA|  9811|\n",
      "|            DELAWARE|  3111|\n",
      "|         CONNECTICUT| 13991|\n",
      "|        NORTH DAKOTA|  1225|\n",
      "|            ARKANSAS|  2873|\n",
      "|             INDIANA| 11278|\n",
      "|             GEORGIA| 44663|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the distribution of our destination_state values. Make sure we didn't accidentally end up with all nulls (for example)\n",
    "i94_clean_df.groupBy('destination_state').count().show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|           port_city| count|\n",
      "+--------------------+------+\n",
      "|              PIEGAN|   140|\n",
      "|         ANDREWS AFB|     4|\n",
      "|           ANZALDUAS|   677|\n",
      "|      FALCON HEIGHTS|     4|\n",
      "|             ORLANDO|149195|\n",
      "|            SAVANNAH|    29|\n",
      "|         TROUT RIVER|    10|\n",
      "|        PEACE BRIDGE|  4035|\n",
      "|        INDIANAPOLIS|   426|\n",
      "|            PROGRESO|    18|\n",
      "|          SAN YSIDRO|  2874|\n",
      "|             ATLANTA| 92579|\n",
      "|            MANASSAS|     2|\n",
      "|     RIO GRANDE CITY|     1|\n",
      "|               MIAMI|343941|\n",
      "|LAREDO COLUMBIA B...|    72|\n",
      "|              HANNAH|     1|\n",
      "|             MEMPHIS|    41|\n",
      "|              NOONAN|     2|\n",
      "|              BLAINE| 11087|\n",
      "|                RENO|     1|\n",
      "|              MOBILE|     3|\n",
      "|             OAKLAND|  3501|\n",
      "|       ST PETERSBURG|   762|\n",
      "|             FORTUNA|     6|\n",
      "|          GREENVILLE|    10|\n",
      "|            PORTLAND|  5108|\n",
      "|         BEEBE PLAIN|     3|\n",
      "|           NIGHTHAWK|     1|\n",
      "|           VANCOUVER| 12706|\n",
      "|              YSLETA|   344|\n",
      "|MOSES LAKE GRANT ...|     3|\n",
      "|        KEAHOLE-KONA|  4042|\n",
      "|           VANCEBORO|     3|\n",
      "|      PORT CANAVERAL|     1|\n",
      "|          FORT MYERS| 17514|\n",
      "|              SAIPAN| 23628|\n",
      "|             DEL RIO|    51|\n",
      "|           ANCHORAGE|    91|\n",
      "|              DENVER| 18260|\n",
      "|       CHRISTIANSTED|   198|\n",
      "|        NORTH CAICOS|  5197|\n",
      "|         COBURN GORE|    37|\n",
      "|             HOULTON|   198|\n",
      "|STEWART - ORANGE ...|     9|\n",
      "|HANSCOM FIELD - B...|    51|\n",
      "|              LAREDO|   355|\n",
      "|               MINOT|     1|\n",
      "|             PHOENIX| 38890|\n",
      "|              BANGOR|   128|\n",
      "|   ST AUGUSTINE ARPT|     2|\n",
      "|           BALTIMORE|  3476|\n",
      "|    NEWARK/TETERBORO|136122|\n",
      "| VETERAN INTL BRIDGE|    79|\n",
      "|                null|101182|\n",
      "|       POINT ROBERTS|   123|\n",
      "|             TORONTO| 20886|\n",
      "|           LUKEVILLE|    89|\n",
      "|     PORT EVERGLADES|  1083|\n",
      "|WILLOW RUN - YPSI...|     1|\n",
      "|             HOUSTON|101481|\n",
      "|           ANACORTES|     1|\n",
      "|               FARGO|     5|\n",
      "|               LIHUE|  2292|\n",
      "|        JACKSONVILLE|    31|\n",
      "|           ROCHESTER|    85|\n",
      "|             MCALLEN|   512|\n",
      "|             DOUGLAS|    64|\n",
      "|              TUCSON|   219|\n",
      "|                ROMA|    12|\n",
      "|              TURNER|     6|\n",
      "|          LONG BEACH|   884|\n",
      "|             SANFORD| 10159|\n",
      "|      PASO DEL NORTE|   232|\n",
      "|       BEECHER FALLS|     7|\n",
      "|          HAKAI PASS|   772|\n",
      "|  BRIDGE OF AMERICAS|   328|\n",
      "|               PHARR|   228|\n",
      "|       EAST RICHFORD|     1|\n",
      "|            HANSBORO|     8|\n",
      "|CANNON INTL - REN...|   255|\n",
      "|           SANTA ANA|  1625|\n",
      "|           MILWAUKEE|   248|\n",
      "|           LANCASTER|    10|\n",
      "|          CHATEAUGAY|     6|\n",
      "|     FORT LAUDERDALE| 95977|\n",
      "|              ROSEAU|    14|\n",
      "|          MORRISTOWN|    20|\n",
      "|          SACRAMENTO|  2201|\n",
      "|            SAN LUIS|    36|\n",
      "|              AUSTIN|  3034|\n",
      "|       GRAND PORTAGE|    51|\n",
      "|         MORSES LINE|    14|\n",
      "|            VICTORIA|   626|\n",
      "|     ST LUCIE COUNTY|    25|\n",
      "|             SHANNON|  3007|\n",
      "|           NASHVILLE|   943|\n",
      "|    HIGHGATE SPRINGS|  1594|\n",
      "|BRADLEY INTERNATI...|    14|\n",
      "|          BELLINGHAM|     4|\n",
      "+--------------------+------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the distribution of port_state values. Make sure we didn't accidentally end up with all nulls (for example)\n",
    "i94_clean_df.groupBy('port_city').count().show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Demographic Data\n",
    "We'll start by renaming the columns and uppercasing the city and state names, to have consistent data formatting across our different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demog_df = demog_df.select(upper(col('City')).alias('city'),\n",
    "                             upper(col('State')).alias('state'),\n",
    "                             col('Median Age').alias('median_age'),\n",
    "                             col('Male Population').alias('male_population'),\n",
    "                             col('Female Population').alias('female_population'),\n",
    "                             col('Total Population').alias('total_population'),\n",
    "                             col('Number of Veterans').alias('total_veterans'),\n",
    "                             col('Foreign-born').alias('foreign_born'),\n",
    "                             col('Average Household Size').alias('average_household_size'),\n",
    "                             col('Race').alias('race'),\n",
    "                             col('Count').alias('race_count')\n",
    "                            ).dropDuplicates().cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "While we may want denormalized data in our fact and dimension tables, we want to make sure that the denormalizations make sense for our purposes. If we look closely, we can observe that the `Race` column in the demographic data has a small number of unnecessarily repeating values. Barring a few anomalies, each cityappears as five separate rows with the same data for every field, except for the `Race` column, and the `Count`, which refers to the total number of residents who identify with the associated race in a given row. \n",
    "\n",
    "To simplify our table and our querying, we can simply pivot the `Race` column, meaning that we would take its five possible values and make each of them a single column. The values in the `Count` column would become the values for the associated `Race` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Turn the Race column into five distinct race columns\n",
    "demog_df = demog_df.groupBy('city',\n",
    "                            'state',\n",
    "                            'median_age',\n",
    "                            'male_population',\n",
    "                            'female_population',\n",
    "                            'total_population',\n",
    "                            'total_veterans', \n",
    "                            'foreign_born', \n",
    "                            'average_household_size'\n",
    "                           ).pivot('race').agg(first('race_count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Tidy the ethnicity column names\n",
    "demog_df = demog_df.select(col('city'),\n",
    "                           col('state'),\n",
    "                           col('median_age'),\n",
    "                           col('male_population'),\n",
    "                           col('female_population'),\n",
    "                           col('total_population'),\n",
    "                           col('total_veterans'),\n",
    "                           col('foreign_born'),\n",
    "                           col('average_household_size').alias('avg_household_size'),\n",
    "                           col('American Indian and Alaska Native').alias('indigenous'),\n",
    "                           col('Asian').alias('asian'),\n",
    "                           col('Black or African-American').alias('black'),\n",
    "                           col('Hispanic or Latino').alias('latinx'),\n",
    "                           col('White').alias('white'),\n",
    "                          ).dropDuplicates().cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demog_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>total_veterans</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>avg_household_size</th>\n",
       "      <th>indigenous</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>latinx</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLOVIS</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>37.8</td>\n",
       "      <td>52392</td>\n",
       "      <td>51780</td>\n",
       "      <td>104172</td>\n",
       "      <td>6173</td>\n",
       "      <td>13409</td>\n",
       "      <td>2.76</td>\n",
       "      <td>1876</td>\n",
       "      <td>14249</td>\n",
       "      <td>3434</td>\n",
       "      <td>23744</td>\n",
       "      <td>78029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CASAS ADOBES</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>44.8</td>\n",
       "      <td>30890</td>\n",
       "      <td>34375</td>\n",
       "      <td>65265</td>\n",
       "      <td>6601</td>\n",
       "      <td>7024</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2047</td>\n",
       "      <td>3009</td>\n",
       "      <td>1854</td>\n",
       "      <td>13609</td>\n",
       "      <td>58956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CONCORD</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>39.6</td>\n",
       "      <td>62310</td>\n",
       "      <td>66358</td>\n",
       "      <td>128668</td>\n",
       "      <td>6287</td>\n",
       "      <td>37428</td>\n",
       "      <td>2.72</td>\n",
       "      <td>1447</td>\n",
       "      <td>17453</td>\n",
       "      <td>6150</td>\n",
       "      <td>41400</td>\n",
       "      <td>92575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FEDERAL WAY</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>36.4</td>\n",
       "      <td>49151</td>\n",
       "      <td>46037</td>\n",
       "      <td>95188</td>\n",
       "      <td>7135</td>\n",
       "      <td>18565</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2396</td>\n",
       "      <td>16026</td>\n",
       "      <td>15495</td>\n",
       "      <td>14049</td>\n",
       "      <td>59035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OVERLAND PARK</td>\n",
       "      <td>KANSAS</td>\n",
       "      <td>38.2</td>\n",
       "      <td>93355</td>\n",
       "      <td>93156</td>\n",
       "      <td>186511</td>\n",
       "      <td>10461</td>\n",
       "      <td>21407</td>\n",
       "      <td>2.41</td>\n",
       "      <td>1264</td>\n",
       "      <td>17123</td>\n",
       "      <td>10685</td>\n",
       "      <td>10104</td>\n",
       "      <td>161153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            city       state  median_age  male_population  female_population  \\\n",
       "0         CLOVIS  CALIFORNIA        37.8            52392              51780   \n",
       "1   CASAS ADOBES     ARIZONA        44.8            30890              34375   \n",
       "2        CONCORD  CALIFORNIA        39.6            62310              66358   \n",
       "3    FEDERAL WAY  WASHINGTON        36.4            49151              46037   \n",
       "4  OVERLAND PARK      KANSAS        38.2            93355              93156   \n",
       "\n",
       "   total_population  total_veterans  foreign_born  avg_household_size  \\\n",
       "0            104172            6173         13409                2.76   \n",
       "1             65265            6601          7024                2.24   \n",
       "2            128668            6287         37428                2.72   \n",
       "3             95188            7135         18565                2.68   \n",
       "4            186511           10461         21407                2.41   \n",
       "\n",
       "   indigenous  asian  black  latinx   white  \n",
       "0        1876  14249   3434   23744   78029  \n",
       "1        2047   3009   1854   13609   58956  \n",
       "2        1447  17453   6150   41400   92575  \n",
       "3        2396  16026  15495   14049   59035  \n",
       "4        1264  17123  10685   10104  161153  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demog_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Temperature Data\n",
    "\n",
    "We saw in our data exploration that there were rows with missing AverageTemperature. These rows will be useless for our purposes, so we will drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_df=temp_df.filter(temp_df.AverageTemperature != 'NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We will also see shortly in our data model that the columns `AverageTemperatureUncertainty`, `Latitude` and `Longitude` are not relevant to our inquiry, so we will drop them and take the opportunity to rename our remaining columns, as well as to upprecase the city and country values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_df = temp_df.select(col('dt').alias('date'),\n",
    "                             col('AverageTemperature').alias('avg_temperature'),\n",
    "                             upper(col('City')).alias('city'),\n",
    "                             upper(col('Country')).alias('country')\n",
    "                            ).dropDuplicates().cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Additionally, our i94 dataset is specific to the year 2016. Our inquiry concerns itself with the factors that may have influenced visitors to choose the destinations they chose. The temperature dataset contains data from as far back as 1743. For our context, we will assume that people would not concern themselves with average temperatures more than 10 years old when choosing where to go in the short term. Hence, we will drop historical data from before 2006."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop pre-2006 data, and make sure the date field doesn't get a midnight timestamp added (useless for our purposes)\n",
    "temp_df = temp_df.filter(temp_df.date >= '2006-01-01').withColumn('date', to_date(col('date'), 'yyyy-MM-dd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323360"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>-9.868</td>\n",
       "      <td>ASTRAKHAN</td>\n",
       "      <td>RUSSIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>14.363</td>\n",
       "      <td>COSTA MESA</td>\n",
       "      <td>UNITED STATES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>20.465</td>\n",
       "      <td>BALESHWAR</td>\n",
       "      <td>INDIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>26.955</td>\n",
       "      <td>BACOLOD</td>\n",
       "      <td>PHILIPPINES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-02-01</td>\n",
       "      <td>-15.714</td>\n",
       "      <td>BAOSHAN</td>\n",
       "      <td>CHINA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  avg_temperature        city        country\n",
       "0  2006-01-01           -9.868   ASTRAKHAN         RUSSIA\n",
       "1  2006-01-01           14.363  COSTA MESA  UNITED STATES\n",
       "2  2006-01-01           20.465   BALESHWAR          INDIA\n",
       "3  2006-01-01           26.955     BACOLOD    PHILIPPINES\n",
       "4  2006-02-01          -15.714     BAOSHAN          CHINA"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 3: Define the Data Model\n",
    "### 3.1 Conceptual Data Model\n",
    "Data will be transferred into a star schema (one fact table where each dimension tables is referenced by a row; additional, derived information can also be added to the fact table). This schema design facilitates analytical querying, as it denormalizes data according to the particular aspects of the data we want to dig further into. In other words, it's optimized to minimize the number of JOINs required to query the data. \n",
    "\n",
    "#### Fact Table\n",
    "\n",
    "**visits_fact** - immigration events\n",
    "- visit_id, immigration_id, port_code, arrival_date, length_of_stay\n",
    "\n",
    "#### Dimension Tables\n",
    "\n",
    "**immigrations_dim** - i94 immigration details\n",
    "- immigration_id, age, gender, citizenship_country, residence_country, arrival_date, departure_date, visa_type, admitted_until, port_of_entry, port_city, port_state, port_country, destination_state\n",
    "\n",
    "**demographics_dim** - demographic data per major US city\n",
    "- city_id, port_code, city, state, median_age, male_population, female_population, total_population, total_veterans, foreign_born, avg_household_size, indigenous, asian, black, latinx, white\n",
    "\n",
    "**temperature_dim** - average temperatures per month from 2006-2013 for global cities\n",
    "- temperature_id, port_code, date, avg_temperature, city, country\n",
    "\n",
    "**date_dim** - dates of arrivals for visits\n",
    "- date, day, week, month, year, weekday\n",
    "\n",
    "![data model](./pipeline_star_schema.jpg \"data model\")\n",
    "\n",
    "### 3.2 Mapping Out Data Pipelines\n",
    "The steps necessary to pipeline the data into the above data model are the following:\n",
    "1. Clean the i94, temperature and demographics datasets (already performed)\n",
    "2. Create a date_dim dimension table based on the arrival_date values in the immigrations table, and extract the desired fields\n",
    "3. Create temperature_dim dimension table: \n",
    "    1. Load the existing, cleaned up temperature table, adding a unique id column\n",
    "    2. Add a port_code field based on the city value\n",
    "4. Create a demographic_dim dimension table:\n",
    "    1. Load the existing, cleaned up demographics table, adding a unique id column\n",
    "    2. Add a port_code field based on the city value\n",
    "5. Create the immigrations_dim table by loading the i94 table (we did a thorough job cleaning it up, knowing ahead of time what our data model was going to be; it already looks how we want it to)\n",
    "6. Create the visits_fact table with a derived length_of_stay column, mapping immigration_id from immigrations_dim, a port_code that can be referenced in temperature_dim and demographics_dim, and the arrival_date associated with the immigration_id\n",
    "7. Write these tables to parquet files that can be queried for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 4: Run Pipelines to Model the Data \n",
    "### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create date_dim table\n",
    "date_dim_df = i94_clean_df.withColumn('date', col('arrival_date'))\\\n",
    "                .withColumn('day', dayofmonth('arrival_date'))\\\n",
    "                .withColumn('week', weekofyear('arrival_date'))\\\n",
    "                .withColumn('month', month('arrival_date'))\\\n",
    "                .withColumn('year', year('arrival_date'))\\\n",
    "                .withColumn('weekday', dayofweek('arrival_date'))\n",
    "                        \n",
    "date_dim_df = date_dim_df.select('date', 'day', 'week', 'month', 'year', 'weekday').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# UDF to add a port_code column to our temperature and demographics tables\n",
    "@udf()\n",
    "def get_city_port(city):\n",
    "    \"\"\"\n",
    "    Return the port code associated with input city\n",
    "    \"\"\"\n",
    "    for key in port_cities:\n",
    "        if city in port_cities[key]:\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create temperature_dim table\n",
    "temperature_dim_df = temp_df.select(monotonically_increasing_id().alias('temperature_id'),\n",
    "                                    col('date'),\n",
    "                                    col('avg_temperature'),\n",
    "                                    col('city'),\n",
    "                                    col('country'),\n",
    "                                   ).withColumn('port_code', get_city_port(temp_df.city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create demographics_dim table\n",
    "demographics_dim_df = demog_df.select(monotonically_increasing_id().alias('city_id'),\n",
    "                                    col('city'),\n",
    "                                    col('state'),\n",
    "                                    col('median_age'),\n",
    "                                    col('male_population'),\n",
    "                                    col('female_population'),\n",
    "                                    col('total_population'),\n",
    "                                    col('total_veterans'),\n",
    "                                    col('foreign_born'),\n",
    "                                    col('avg_household_size'),\n",
    "                                    col('indigenous'),\n",
    "                                    col('asian'),\n",
    "                                    col('black'),\n",
    "                                    col('latinx'),\n",
    "                                    col('white'),\n",
    "                                   ).withColumn('port_code', get_city_port(demog_df.city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create immigrations_dim table\n",
    "immigrations_dim_df = i94_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create visits_fact table\n",
    "from pyspark.sql.functions import datediff\n",
    "\n",
    "visits_fact_df = immigrations_dim_df.select(monotonically_increasing_id().alias('visit_id'),\n",
    "                                    col('immigration_id'),\n",
    "                                    col('port_of_entry').alias('port_code'),\n",
    "                                    col('arrival_date'),\n",
    "                                    datediff(col('departure_date'),col('arrival_date')).alias('length_of_stay')\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create parquet files for analysis\n",
    "%rm -rf ./results/\n",
    "immigrations_dim_df.write.mode('append').partitionBy('age').parquet('./results/immigrations_dim.parquet')\n",
    "demographics_dim_df.write.mode('append').partitionBy('state').parquet('./results/demographics_dim.parquet')\n",
    "temperature_dim_df.write.mode('append').partitionBy('country').parquet('./results/temperature_dim.parquet')\n",
    "date_dim_df.write.mode('append').parquet('./results/date_dim.parquet')\n",
    "visits_fact_df.write.mode('append').partitionBy('arrival_date').parquet('./results/visits_fact.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.2 Data Quality Checks\n",
    "Our quality checks will consist of:\n",
    "* Ensuring the tables exist\n",
    "* Ensuring they contain content\n",
    "* Source and count checks to ensure completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tables exist\n"
     ]
    }
   ],
   "source": [
    "tables = [immigrations_dim_df, demographics_dim_df, temperature_dim_df, date_dim_df, visits_fact_df]\n",
    "# Ensure tables exist\n",
    "helpers.tables_exist(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe at index 0 contains 3096313 rows\n",
      "Dataframe at index 1 contains 596 rows\n",
      "Dataframe at index 2 contains 323360 rows\n",
      "Dataframe at index 3 contains 30 rows\n",
      "Dataframe at index 4 contains 3096313 rows\n",
      "All tables contain content\n"
     ]
    }
   ],
   "source": [
    "# Check the row counts\n",
    "helpers.tables_contain_data(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Ensure parquet files look how we expect\n",
    "immigration_parquet = spark.read.parquet('./results/immigrations_dim.parquet')\n",
    "demographics_parquet= spark.read.parquet('./results/demographics_dim.parquet')\n",
    "temperature_parquet = spark.read.parquet('./results/temperature_dim.parquet')\n",
    "date_parquet = spark.read.parquet('./results/date_dim.parquet')\n",
    "visits_parquet = spark.read.parquet('./results/visits_fact.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>immigration_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>citizenship_country</th>\n",
       "      <th>residence_country</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>visa_type</th>\n",
       "      <th>admitted_until</th>\n",
       "      <th>port_of_entry</th>\n",
       "      <th>port_city</th>\n",
       "      <th>port_state</th>\n",
       "      <th>port_country</th>\n",
       "      <th>destination_state</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5196137.0</td>\n",
       "      <td>None</td>\n",
       "      <td>ECUADOR</td>\n",
       "      <td>ECUADOR</td>\n",
       "      <td>2016-04-27</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-10-26</td>\n",
       "      <td>FMY</td>\n",
       "      <td>FORT MYERS</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3645361.0</td>\n",
       "      <td>F</td>\n",
       "      <td>ECUADOR</td>\n",
       "      <td>ECUADOR</td>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>2016-05-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-10-18</td>\n",
       "      <td>FMY</td>\n",
       "      <td>FORT MYERS</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>427529.0</td>\n",
       "      <td>F</td>\n",
       "      <td>ECUADOR</td>\n",
       "      <td>ECUADOR</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>2016-04-10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>FMY</td>\n",
       "      <td>FORT MYERS</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3133889.0</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>GERMANY</td>\n",
       "      <td>2016-04-17</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-07-15</td>\n",
       "      <td>FMY</td>\n",
       "      <td>FORT MYERS</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3134089.0</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>GERMANY</td>\n",
       "      <td>2016-04-17</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-07-15</td>\n",
       "      <td>FMY</td>\n",
       "      <td>FORT MYERS</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   immigration_id gender citizenship_country residence_country arrival_date  \\\n",
       "0       5196137.0   None             ECUADOR           ECUADOR   2016-04-27   \n",
       "1       3645361.0      F             ECUADOR           ECUADOR   2016-04-19   \n",
       "2        427529.0      F             ECUADOR           ECUADOR   2016-04-02   \n",
       "3       3133889.0      F                None           GERMANY   2016-04-17   \n",
       "4       3134089.0      F                None           GERMANY   2016-04-17   \n",
       "\n",
       "  departure_date  visa_type admitted_until port_of_entry   port_city  \\\n",
       "0     2016-04-28        2.0     2016-10-26           FMY  FORT MYERS   \n",
       "1     2016-05-07        2.0     2016-10-18           FMY  FORT MYERS   \n",
       "2     2016-04-10        2.0     2016-10-01           FMY  FORT MYERS   \n",
       "3     2016-04-22        2.0     2016-07-15           FMY  FORT MYERS   \n",
       "4     2016-04-23        2.0     2016-07-15           FMY  FORT MYERS   \n",
       "\n",
       "  port_state   port_country destination_state   age  \n",
       "0    FLORIDA  UNITED STATES          NEW YORK  30.0  \n",
       "1    FLORIDA  UNITED STATES          NEW YORK  30.0  \n",
       "2    FLORIDA  UNITED STATES          NEW YORK  30.0  \n",
       "3    FLORIDA  UNITED STATES          NEW YORK  30.0  \n",
       "4    FLORIDA  UNITED STATES          NEW YORK  30.0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_parquet.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_id</th>\n",
       "      <th>city</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>total_veterans</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>avg_household_size</th>\n",
       "      <th>indigenous</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>latinx</th>\n",
       "      <th>white</th>\n",
       "      <th>port_code</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249108103170</td>\n",
       "      <td>AUGUSTA-RICHMOND COUNTY CONSOLIDATED GOVERNMENT</td>\n",
       "      <td>33.7</td>\n",
       "      <td>94662</td>\n",
       "      <td>101917</td>\n",
       "      <td>196579</td>\n",
       "      <td>19085</td>\n",
       "      <td>7915</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1667</td>\n",
       "      <td>4429</td>\n",
       "      <td>112271</td>\n",
       "      <td>9068</td>\n",
       "      <td>77940</td>\n",
       "      <td>None</td>\n",
       "      <td>GEORGIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197568495619</td>\n",
       "      <td>LOUISVILLE/JEFFERSON COUNTY METRO GOVERNMENT</td>\n",
       "      <td>37.5</td>\n",
       "      <td>298451</td>\n",
       "      <td>316938</td>\n",
       "      <td>615389</td>\n",
       "      <td>39364</td>\n",
       "      <td>37875</td>\n",
       "      <td>2.45</td>\n",
       "      <td>4585</td>\n",
       "      <td>18601</td>\n",
       "      <td>151256</td>\n",
       "      <td>28712</td>\n",
       "      <td>456451</td>\n",
       "      <td>None</td>\n",
       "      <td>KENTUCKY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1340029796355</td>\n",
       "      <td>ATHENS-CLARKE COUNTY UNIFIED GOVERNMENT</td>\n",
       "      <td>26.5</td>\n",
       "      <td>57415</td>\n",
       "      <td>65148</td>\n",
       "      <td>122563</td>\n",
       "      <td>3953</td>\n",
       "      <td>12868</td>\n",
       "      <td>2.44</td>\n",
       "      <td>593</td>\n",
       "      <td>6635</td>\n",
       "      <td>34583</td>\n",
       "      <td>13159</td>\n",
       "      <td>79931</td>\n",
       "      <td>None</td>\n",
       "      <td>GEORGIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>386547056640</td>\n",
       "      <td>BAKERSFIELD</td>\n",
       "      <td>30.6</td>\n",
       "      <td>182154</td>\n",
       "      <td>191473</td>\n",
       "      <td>373627</td>\n",
       "      <td>12284</td>\n",
       "      <td>71575</td>\n",
       "      <td>3.23</td>\n",
       "      <td>7357</td>\n",
       "      <td>31929</td>\n",
       "      <td>34240</td>\n",
       "      <td>180241</td>\n",
       "      <td>272853</td>\n",
       "      <td>BFL</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>386547056641</td>\n",
       "      <td>TORRANCE</td>\n",
       "      <td>41.2</td>\n",
       "      <td>73209</td>\n",
       "      <td>75259</td>\n",
       "      <td>148468</td>\n",
       "      <td>8459</td>\n",
       "      <td>43096</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3638</td>\n",
       "      <td>54317</td>\n",
       "      <td>5906</td>\n",
       "      <td>25699</td>\n",
       "      <td>80498</td>\n",
       "      <td>None</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         city_id                                             city  median_age  \\\n",
       "0   249108103170  AUGUSTA-RICHMOND COUNTY CONSOLIDATED GOVERNMENT        33.7   \n",
       "1   197568495619     LOUISVILLE/JEFFERSON COUNTY METRO GOVERNMENT        37.5   \n",
       "2  1340029796355          ATHENS-CLARKE COUNTY UNIFIED GOVERNMENT        26.5   \n",
       "3   386547056640                                      BAKERSFIELD        30.6   \n",
       "4   386547056641                                         TORRANCE        41.2   \n",
       "\n",
       "   male_population  female_population  total_population  total_veterans  \\\n",
       "0            94662             101917            196579           19085   \n",
       "1           298451             316938            615389           39364   \n",
       "2            57415              65148            122563            3953   \n",
       "3           182154             191473            373627           12284   \n",
       "4            73209              75259            148468            8459   \n",
       "\n",
       "   foreign_born  avg_household_size  indigenous  asian   black  latinx  \\\n",
       "0          7915                2.67        1667   4429  112271    9068   \n",
       "1         37875                2.45        4585  18601  151256   28712   \n",
       "2         12868                2.44         593   6635   34583   13159   \n",
       "3         71575                3.23        7357  31929   34240  180241   \n",
       "4         43096                2.70        3638  54317    5906   25699   \n",
       "\n",
       "    white port_code       state  \n",
       "0   77940      None     GEORGIA  \n",
       "1  456451      None    KENTUCKY  \n",
       "2   79931      None     GEORGIA  \n",
       "3  272853       BFL  CALIFORNIA  \n",
       "4   80498      None  CALIFORNIA  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_parquet.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_id</th>\n",
       "      <th>date</th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>city</th>\n",
       "      <th>port_code</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1425929142276</td>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>15.568</td>\n",
       "      <td>BIKANER</td>\n",
       "      <td>None</td>\n",
       "      <td>INDIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1425929142287</td>\n",
       "      <td>2006-04-01</td>\n",
       "      <td>30.922</td>\n",
       "      <td>DEHRI</td>\n",
       "      <td>None</td>\n",
       "      <td>INDIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1425929142288</td>\n",
       "      <td>2006-04-01</td>\n",
       "      <td>31.169</td>\n",
       "      <td>BHARATPUR</td>\n",
       "      <td>None</td>\n",
       "      <td>INDIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1425929142296</td>\n",
       "      <td>2006-05-01</td>\n",
       "      <td>32.618</td>\n",
       "      <td>BARSI</td>\n",
       "      <td>None</td>\n",
       "      <td>INDIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1425929142299</td>\n",
       "      <td>2006-06-01</td>\n",
       "      <td>29.896</td>\n",
       "      <td>ASANSOL</td>\n",
       "      <td>None</td>\n",
       "      <td>INDIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temperature_id        date  avg_temperature       city port_code country\n",
       "0   1425929142276  2006-01-01           15.568    BIKANER      None   INDIA\n",
       "1   1425929142287  2006-04-01           30.922      DEHRI      None   INDIA\n",
       "2   1425929142288  2006-04-01           31.169  BHARATPUR      None   INDIA\n",
       "3   1425929142296  2006-05-01           32.618      BARSI      None   INDIA\n",
       "4   1425929142299  2006-06-01           29.896    ASANSOL      None   INDIA"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_parquet.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-17</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-27</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-16</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  day  week  month  year  weekday\n",
       "0  2016-04-05    5    14      4  2016        3\n",
       "1  2016-04-28   28    17      4  2016        5\n",
       "2  2016-04-17   17    15      4  2016        1\n",
       "3  2016-04-27   27    17      4  2016        4\n",
       "4  2016-04-16   16    15      4  2016        7"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_parquet.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_id</th>\n",
       "      <th>immigration_id</th>\n",
       "      <th>port_code</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>arrival_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1503238553628</td>\n",
       "      <td>5438406.0</td>\n",
       "      <td>FMY</td>\n",
       "      <td>14</td>\n",
       "      <td>2016-04-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1503238553648</td>\n",
       "      <td>5440711.0</td>\n",
       "      <td>FMY</td>\n",
       "      <td>36</td>\n",
       "      <td>2016-04-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1503238553692</td>\n",
       "      <td>5502052.0</td>\n",
       "      <td>CLG</td>\n",
       "      <td>7</td>\n",
       "      <td>2016-04-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1503238553693</td>\n",
       "      <td>5496942.0</td>\n",
       "      <td>CLG</td>\n",
       "      <td>7</td>\n",
       "      <td>2016-04-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1503238553694</td>\n",
       "      <td>5499134.0</td>\n",
       "      <td>CLG</td>\n",
       "      <td>7</td>\n",
       "      <td>2016-04-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        visit_id  immigration_id port_code  length_of_stay arrival_date\n",
       "0  1503238553628       5438406.0       FMY              14   2016-04-29\n",
       "1  1503238553648       5440711.0       FMY              36   2016-04-29\n",
       "2  1503238553692       5502052.0       CLG               7   2016-04-29\n",
       "3  1503238553693       5496942.0       CLG               7   2016-04-29\n",
       "4  1503238553694       5499134.0       CLG               7   2016-04-29"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visits_parquet.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.3 Data dictionary \n",
    "Data dictionary for our data model.\n",
    "\n",
    "#### immigrations_dim\n",
    "\n",
    "| Field | Description |\n",
    "| --- | --- |\n",
    "| immigration_id | id of respondent record |\n",
    "| age | age of respondent |\n",
    "| gender | gender of respondent |\n",
    "| citizenship_country | respondent's citizenship country |\n",
    "| residence_country | respondent's country of residence |\n",
    "| arrival_date | respondent's arrival date |\n",
    "| departure_date | respondent's departure date |\n",
    "| visa_type | type of visa granted to respondent (values: 1 = business, 2 = pleasure, 3 = student) |\n",
    "| admitted_until | date until which respondent is permitted to stay |\n",
    "| port_of_entry | respondent's port of entry port code |\n",
    "| port_city | city denoted by port_of_entry |\n",
    "| port_state | state denoted by port_of_entry |\n",
    "| port_country | country denoted by port_of_entry |\n",
    "| destination_state | state where the respondent intends to stay | \n",
    "\n",
    "#### demographics_dim\n",
    "\n",
    "| Field | Description |\n",
    "| --- | --- |\n",
    "| city_id | id of city demographics record |\n",
    "| port_code | port code associated with this city, if applicable |\n",
    "| city | the name of the city |\n",
    "| state | city's state |\n",
    "| median_age | city's median citizen age |\n",
    "| male_population | total male population for this city |\n",
    "| female_population | total female population for this city |\n",
    "| total_population | total population for this city |\n",
    "| total_veterans | number of veterans in this city |\n",
    "| foreign_born | number of residents who are foreign-born |\n",
    "| avg_household_size | average household size for this city |\n",
    "| indigenous | number of residents who are American Indian and Alaska Native |\n",
    "| asian | number of residents who are Asian |\n",
    "| black | number of residents who are Black or African-American | \n",
    "| latinx | number of residents who are Hispanic or Latinx |\n",
    "| white | number of residents who are White |\n",
    "\n",
    "#### temperature_dim\n",
    "\n",
    "| Field | Description |\n",
    "| --- | --- |\n",
    "| temperature_id | id of temperature record |\n",
    "| port_code | port code associated with this temperature record's city, if applicable |\n",
    "| date | the date of this temperature record |\n",
    "| avg_temperature | average temperature measured during the month of this temperature record |\n",
    "| city | the name of the city of this temperature record |\n",
    "| country | the name of the country of this temperature record |\n",
    "\n",
    "#### date_dim\n",
    "\n",
    "| Field | Description |\n",
    "| --- | --- |\n",
    "| date | yyyy-MM-dd value; also serves as the id of this date record |\n",
    "| day | day of month for this date record (numeric value) |\n",
    "| week | week of year for this date record (numeric value) |\n",
    "| month | month of year for this date record (numeric value) |\n",
    "| year | year of this date record |\n",
    "| weekday | day of week of this date record (numeric value) |\n",
    "\n",
    "#### visits_fact\n",
    "\n",
    "| Field | Description |\n",
    "| --- | --- |\n",
    "| visit_id | id of visit record |\n",
    "| immigration_id | references an immigrations_dim id; each record from immigrations_dim represents a visit in visits_fact |\n",
    "| port_code | port_of_entry for the referenced immigrations_dim record |\n",
    "| arrival_date | arrival_date for the referenced immigrations_dim record |\n",
    "| length_of_stay | number of days between arrival_date and departure_date for this visitor's immigrations_dim record |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 5: Discussion\n",
    "\n",
    "### Tools Rationale\n",
    "\n",
    "Spark was chosen for this project because of its ability to process large amounts of data in a distributed cluster and the ease with which in can scale. Our source datasets are quite large, and they would be even larger if we were using the complete i94 dataset, rather than limiting ourselves to a single month. The final tables were written out as parquet files, but they could also be loaded into a Redshift cluster. \n",
    "\n",
    "### Data updates\n",
    "\n",
    "The data here represent a moment in time, but if this were a pipeline that was meant to be maintained, with regularly updated data sources, we could update our data at regular intervals. The data update schedule would depend on how often our sources are updated and how vital for our business or research needs it would be to have up to the moment data. The core piece of data in this project is the immigration data, so if it is updated annually, an annual update cycle would make sense. If it is updated monthly, we could update monthly, as long as we understand that some of our other data sources, such as the demographic data (which is extracted from census data), would not be updated as frequently.\n",
    "\n",
    "### What if...\n",
    "#### ...the data was increased by 100x?\n",
    "Then we should make sure to set up the contents of this notebook as a Python script that can be run in an EMR cluster, so that we can scale according to our needs.\n",
    "\n",
    "#### ... the data populates a dashboard that must be updated on a daily basis by 7am every day?\n",
    "Then we would really benefit from relying on an automated pipeline scheduler and job runner like Airflow.\n",
    "\n",
    "#### ...the database needed to be accessed by 100+ people?\n",
    "Then moving our data to a Redshift cluster hosted in the cloud would allow for scaling as our numbers of users and reads increase."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
